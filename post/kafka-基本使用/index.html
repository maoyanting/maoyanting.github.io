<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <link href="//gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.57.2" />

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Kafka-基本使用 &middot; 修仙下属委员会</title>

  
  <link type="text/css" rel="stylesheet" href="https://maoyanting.github.io/css/print.css" media="print">
  <link type="text/css" rel="stylesheet" href="https://maoyanting.github.io/css/poole.css">
  <link type="text/css" rel="stylesheet" href="https://maoyanting.github.io/css/syntax.css">
  <link type="text/css" rel="stylesheet" href="https://maoyanting.github.io/css/hyde.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">



  <link href="https://cdn.bootcss.com/highlight.js/9.12.0/styles/monokai.min.css" rel="stylesheet">
<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="修仙下属委员会" />

  
</head>

  <body class=" ">
  <aside class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="https://maoyanting.github.io/"><h1>修仙下属委员会</h1></a>
      <p class="lead">
      前给排水工程师现程序媛 
      <a href="http://hugo.spf13.com">hugo</a> made by <a href="http://twitter.com/mdo">@mdo</a>. 
      </p>
    </div>

    <nav>
      <ul class="sidebar-nav">
        <li><a href="https://maoyanting.github.io/">Home</a> </li>
        <li><a href="https://maoyanting.github.io//categories/index.html">Categories</a> </li>
        <li><a href="https://maoyanting.github.io//about/index.html">About Me</a> </li>
        <li><a href="/posts/"> Blog </a></li><li><a href="/categories/"> Categories </a></li><li><a href="/about"> About </a></li>
      </ul>
    </nav>

    <p>&copy; 2020. All rights reserved. </p>
  </div>
</aside>

    <main class="content container">
    <div class="post">
  <h1>Kafka-基本使用</h1>
  <div id="toc" class="well col-md-4 col-sm-6">
    <nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#摘要">摘要</a>
<ul>
<li>
<ul>
<li><a href="#download-the-code">Download the code</a></li>
<li><a href="#start-the-server">Start the server</a></li>
<li><a href="#create-a-topic">Create a topic</a></li>
<li><a href="#send-some-messages">Send some messages</a></li>
<li><a href="#start-a-consumer">Start a consumer</a></li>
<li><a href="#setting-up-a-multi-broker-cluster">Setting up a multi-broker cluster</a></li>
<li><a href="#use-kafka-connect-to-import-export-data">Use Kafka Connect to import/export data</a></li>
<li><a href="#use-kafka-streams-to-process-data">Use Kafka Streams to process data</a></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</nav>
    </div>
  <time datetime=2018-01-08T11:27:46Z class="post-date">Mon, Jan 8, 2018</time>
  <h2 id="摘要">摘要</h2>

<p>Kafka最简单的使用</p>

<h4 id="download-the-code">Download the code</h4>

<p>下载解压缩并打开</p>

<p><code>cd kafka_2.11-1.0.0</code></p>

<h4 id="start-the-server">Start the server</h4>

<p>安装使用zookeeper，可使用自带的或者自己编辑的</p>

<p><code>bin/zookeeper-server-start.sh config/zookeeper.properties</code></p>

<p>然后启动Kafka</p>

<p><code>bin/kafka-server-start.sh config/server.properties</code></p>

<h4 id="create-a-topic">Create a topic</h4>

<p>新建一个Topic，名字叫&rdquo;test&rdquo;,只有一个分区和一个备份。</p>

<pre><code>bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
</code></pre>

<p>查看存在的Topic列表</p>

<p><code>bin/kafka-topics.sh --list --zookeeper localhost:2181</code></p>

<p>除了手动创建topics，你还可以配置brokers，在一个不存在的topic发表的时候自动创建对应的topic。</p>

<h4 id="send-some-messages">Send some messages</h4>

<p>Kafka提供了一个命令行的工具，可以从输入文件或者命令行中读取消息并发送给Kafka集群。每一行是一条消息。</p>

<pre><code>bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
This is a message
This is another message
</code></pre>

<h4 id="start-a-consumer">Start a consumer</h4>

<p>Kafka也提供了一个消费消息的命令行工具。</p>

<pre><code>bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
This is a message
This is another message
</code></pre>

<p>如果你上面的命令运行在两个不同的终端，那么你现在应该能够进入消息生产者终端，并看到他们出现在消费者终端。</p>

<p>这些命令行工具有很多的选项，你可以查看他们的文档来了解更多的功能。</p>

<h4 id="setting-up-a-multi-broker-cluster">Setting up a multi-broker cluster</h4>

<p>目前我们一直运行在一个broker上，不好玩。</p>

<p>对于Kafka来说，一个 broker只是表示cluster的大小为1，多几个broker并不会有什么变化。</p>

<p>让我们扩大集群为三个节点(仍然运行在我们的本地机器上)。</p>

<p>首先为每个broker创建一个配置文件。</p>

<pre><code>cp config/server.properties config/server-1.properties
cp config/server.properties config/server-2.properties
</code></pre>

<p>现在编辑这些新的文件，设置以下属性:</p>

<pre><code>config/server-1.properties:
    broker.id=1
    port=9093
    log.dir=/tmp/kafka-logs-1
 
config/server-2.properties:
    broker.id=2
    port=9094
    log.dir=/tmp/kafka-logs-2
</code></pre>

<p>broker.id属性别重样，这个也是集群中每个节点的唯一不可修改的名字。</p>

<p>为了在一台机器上启动两个broker，改了一下它们的port的。
Zookeeper还在，上面用的broker还活着。 来启动这两个broker.</p>

<pre><code>&gt; bin/kafka-server-start.sh config/server-1.properties &amp;
...
&gt; bin/kafka-server-start.sh config/server-2.properties &amp;
...
</code></pre>

<p>创建一个新的topic，把备份设置为3:</p>

<pre><code>&gt; bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic
</code></pre>

<p>成功了，但是我们怎么知道这个broker能做什么呢？运行 &ldquo;describe topics&rdquo; 命令看看：</p>

<pre><code>&gt; bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic
Topic:my-replicated-topic	PartitionCount:1	ReplicationFactor:3	Configs:
	Topic: my-replicated-topic	Partition: 0	Leader: 1	Replicas: 1,2,0	Isr: 1,2,0
</code></pre>

<p>总结一下：第一行给出了partitions的汇总信息。剩下每一行显示一个partition的信息。因为我们只有一个partition，这个 topic只有一行。</p>

<p>来看看一开始创建的节点:</p>

<ul>
<li>&ldquo;leader&rdquo;node负责所有的读和写的partitions。每个node将负责一个随机分配的partition。</li>
<li>&ldquo;replicas&rdquo; 是node的列表。复制了partition的日志，不管node是死是活，是否是leader，包含了所有的node。</li>
<li>&ldquo;isr&rdquo; 是工作中的复制节点的集合，也就是活的节点的集合。</li>
</ul>

<p>在我们的例子中，node1是我们topic唯一partition的leader。</p>

<p>我们可以在之前的topic运行相同的命令：</p>

<pre><code>&gt; bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test
Topic:test	PartitionCount:1	ReplicationFactor:1	Configs:
	Topic: test	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
</code></pre>

<p>很明显的是，我们之前的topic没有replicas，运行在我们创建它时生成的唯一一个服务器上。</p>

<p>我们用新的topic发布一点消息</p>

<pre><code>&gt; bin/kafka-console-producer.sh --broker-list localhost:9092 --topic my-replicated-topic
...
my test message 1
my test message 2
^C
</code></pre>

<p>然后消费它：</p>

<pre><code>&gt; bin/kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic my-replicated-topic
...
my test message 1
my test message 2
^C
</code></pre>

<p>测试一下容错.。杀掉leader，也就是Broker 1:</p>

<pre><code>&gt; ps | grep server-1.properties
7564 ttys002    0:15.91 /System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/bin/java...
&gt; kill -9 7564
</code></pre>

<p>Leader被切换到一个follower节点，node 1 不会被列在isr中了，因为它死了:</p>

<pre><code>&gt; bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic
Topic:my-replicated-topic	PartitionCount:1	ReplicationFactor:3	Configs:
	Topic: my-replicated-topic	Partition: 0	Leader: 2	Replicas: 1,2,0	Isr: 2,0
</code></pre>

<p>但是消息还是可以消费的：</p>

<p>(But the messages are still available for consumption even though the leader that took the writes originally is down:)</p>

<pre><code>&gt; bin/kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic my-replicated-topic
...
my test message 1
my test message 2
^C
</code></pre>

<h4 id="use-kafka-connect-to-import-export-data">Use Kafka Connect to import/export data</h4>

<p>从控制台写入数据和写回控制台是一个简单的操作，但是你可能想要使用从别的地方来的数据或从 Kafka导出数据到其他系统。对于许多系统，相对于编写自定义集成代码而言，你还可以使用 Kafka Connect导入或导出数据。</p>

<p>Kafka Connect是一种包含在Kafka内，用于导入和导出数据的工具。它是一个可扩展的工具，运行连接器，实现与外部系统交互的自定义逻辑。接下来我们将看到如何运行Kafka Connect，导入的数据文件到Kafka的topic和导出数据到一个文件。</p>

<p>首先,我们将首先创建一些数据用于测试:</p>

<pre><code>&gt; echo -e &quot;foo\nbar&quot; &gt; test.txt
</code></pre>

<p>接下来，我们将两个connector以独立模式运行，这意味着它们的运行过程是单一的，本地的，专用的。</p>

<p>我们提供三个配置文件作为参数。</p>

<p>第一个总是Kafka Connect过程的配置文件，包含常见的配置如Kafka brokers连接和数据的序列化格式。</p>

<p>剩下的每个配置文件指定一个connector创建。这些文件包括一个独特的connector名称，connector类实例化和任何connector要求的其他配置。</p>

<pre><code>&gt; bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties
</code></pre>

<p>这些Kafka的示例配置文件，使用默认的本地集群配置（你之前使用过），创建两个connector：</p>

<p>第一种是source connector，从输入文件中依行读取，并存入Kafka topic中。</p>

<p>第二个是sink connector，从Kafka的topic读取消息，并将每一行输出到文件。</p>

<p>在启动期间，你将看到大量的日志消息，包括一些消息显示connectors被实例化。一旦Kafka Connect过程已经开始，source connector应该开始读取test.txt并放入的名为connect-test的topic，sink connector应该从名为connect-test的topic开始阅读消息，并写入test.sink.txt。</p>

<p>我们可以验证数据已经通过整个pipeline用以检查输出文件的内容：</p>

<pre><code>&gt; more test.sink.txt
foo
bar
</code></pre>

<p>数据被存储在 Kafka的connect-test topic，所以我们也可以运行一个消费者控制台，看到topic中的数据(或消费者使用自定义代码来处理):</p>

<pre><code>&gt; bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic connect-test --from-beginning
{&quot;schema&quot;:{&quot;type&quot;:&quot;string&quot;,&quot;optional&quot;:false},&quot;payload&quot;:&quot;foo&quot;}
{&quot;schema&quot;:{&quot;type&quot;:&quot;string&quot;,&quot;optional&quot;:false},&quot;payload&quot;:&quot;bar&quot;}
...
</code></pre>

<p>connectors继续处理数据，所以我们可以将数据添加到文件，并看到它穿过pipeline：</p>

<pre><code>&gt; echo Another line&gt;&gt; test.txt
</code></pre>

<p>您应该看到线出现在控制台消费者输出和文件中。</p>

<h4 id="use-kafka-streams-to-process-data">Use Kafka Streams to process data</h4>

<p>Kafka Streams is a client library for building mission-critical real-time applications and microservices, where the input and/or output data is stored in Kafka clusters. Kafka Streams combines the simplicity of writing and deploying standard Java and Scala applications on the client side with the benefits of Kafka&rsquo;s server-side cluster technology to make these applications highly scalable, elastic, fault-tolerant, distributed, and much more. This quickstart will demonstrate how to run a streaming application coded in this library.</p>

<p>Kafka Streams 是一个客户端库，用于构建实时任务关键型应用程序，microservices输入和/或输出的数据存储在Kafka clusters。Kafka Streams结合简单的编写和部署标准Java和Scala应用程序在客户端与卡夫卡的服务器集群技术，使这些应用程序高度可伸缩的，弹性、容错、分布式、等等。本<a href="https://kafka.apache.org/10/documentation/streams/quickstart" rel="nofollow noreferrer" target="_blank">快速入门</a>将演示如何运行一个流媒体应用程序编码在这个library。</p>
</div>


<h2>Comments</h2>
<div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "yourdiscussshortname" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </main>

    
  </body>
</html>
