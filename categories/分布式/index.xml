<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>分布式 on 修仙下属委员会</title>
    <link>https://maoyanting.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/</link>
    <description>Recent content in 分布式 on 修仙下属委员会</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 10 Jan 2018 09:26:50 +0000</lastBuildDate>
    
	<atom:link href="https://maoyanting.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>KafKa-在Spring中的使用</title>
      <link>https://maoyanting.github.io/post/kafka-%E5%9C%A8spring%E4%B8%AD%E7%9A%84%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Wed, 10 Jan 2018 09:26:50 +0000</pubDate>
      
      <guid>https://maoyanting.github.io/post/kafka-%E5%9C%A8spring%E4%B8%AD%E7%9A%84%E4%BD%BF%E7%94%A8/</guid>
      <description>&lt;h2 id=&#34;写在前面&#34;&gt;写在前面&lt;/h2&gt;

&lt;p&gt;Kafka的简单介绍可以看&lt;a href=&#34;http://www.infoq.com/cn/articles/depth-interpretation-of-kafka-data-reliability&#34;&gt;这个博客&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Kafka的简单使用可参看之前的&lt;a href=&#34;https://maoyanting.github.io/2018/01/08/kafka%E5%AE%89%E8%A3%85%EF%BC%88%E7%BF%BB%E8%AF%91%EF%BC%89/&#34;&gt;KafKa安装（翻译）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Spring for Kafka 的简单使用可参看&lt;a href=&#34;https://my.oschina.net/zhengweishan/blog/736213&#34;&gt;这个博客&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这里放一张我自己弄的简单的图&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/maoyanting/readme_pic/blob/master/kafka%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.png?raw=true&#34; alt=&#34;kafka基础知识&#34; /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kafka-基本使用</title>
      <link>https://maoyanting.github.io/post/kafka-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Mon, 08 Jan 2018 11:27:46 +0000</pubDate>
      
      <guid>https://maoyanting.github.io/post/kafka-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</guid>
      <description>&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;

&lt;p&gt;Kafka最简单的使用&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kafka-内部分析</title>
      <link>https://maoyanting.github.io/post/kafka-%E5%86%85%E9%83%A8%E5%88%86%E6%9E%90/</link>
      <pubDate>Fri, 05 Jan 2018 11:27:46 +0000</pubDate>
      
      <guid>https://maoyanting.github.io/post/kafka-%E5%86%85%E9%83%A8%E5%88%86%E6%9E%90/</guid>
      <description>简介 设计目标 1、以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间复杂度的访问性能。
2、高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条以上消息的传输。
3、支持Kafka Server间的消息分区，及分布式消费，同时保证每个Partition内的消息顺序传输。
4、同时支持离线数据处理和实时数据处理。
5、Scale out：支持在线水平扩展。
结构 Kafka通过Zookeeper管理集群配置，选举leader
在Consumer Group发生变化时进行rebalance。
Producer使用push模式将消息发布到broker，
Consumer使用pull模式从broker订阅并消费消息。
Topic &amp;amp; Partition Topic在逻辑上可以被认为是一个queue，每条消费都必须指定它的Topic，可以简单理解为必须指明把这条消息放进哪个queue里。为了使得Kafka的吞吐率可以线性提高，物理上把Topic分成一个或多个Partition，每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件。
🔔若创建topic1和topic2两个topic，且分别有13个和19个分区，则整个集群上会相应会生成共32个文件夹（本文所用集群共8个节点，此处topic1和topic2 replication-factor均为1）。
每个日志文件都是一个log entrie序列
每个log entry包含一个4字节整型数值（值为N+5），1个字节的&amp;rdquo;magic value&amp;rdquo;，4个字节的CRC校验码，其后跟N个字节的消息体。
每条消息都有一个当前Partition下唯一的64字节的offset，它指明了这条消息的起始位置。磁盘上存储的消息格式如下：
message length ： 4 bytes (value: 1+4+n) &amp;quot;magic&amp;quot; value ： 1 byte crc ： 4 bytes payload ： n bytes  这个log entries并非由一个文件构成，而是分成多个segment，每个segment以该segment第一条消息的offset命名并以“.kafka”为后缀。
另外会有一个索引文件，它标明了每个segment下包含的log entry的offset范围，如下图所示。
效率： 因为每条消息都被append到该Partition中，属于顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。
因为Kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，删除过期文件与提高Kafka性能无关。选择怎样的删除策略只与磁盘以及具体的需求有关。
另外，Kafka会为每一个Consumer Group保留一些metadata信息——当前消费的消息的position，也即offset。这个offset由Consumer控制。正常情况下Consumer会在消费完一条消息后递增该offset。当然，Consumer也可将offset设成一个较小的值，重新消费一些消息。因为offet由Consumer控制，所以Kafka broker是无状态的，它不需要标记哪些消息被哪些消费过，也不需要通过broker去保证同一个Consumer Group只有一个Consumer能消费某一条消息，因此也就不需要锁机制，这也为Kafka的高吞吐率提供了有力保障。
关于已经被消费的消息： 对于传统的message queue而言，一般会删除已经被消费的消息，而Kafka集群会保留所有的消息，无论其被消费与否。
当然，因为磁盘限制，不可能永久保留所有数据（实际上也没必要），因此Kafka提供两种策略删除旧数据。
一是基于时间
二是基于Partition文件大小。
🔔可以通过配置$KAFKA_HOME/config/server.properties，让Kafka删除一周前的数据，也可在Partition文件超过1GB时删除旧数据。
Producer消息路由 Producer发送消息到broker时，会根据Paritition机制选择将其存储到哪一个Partition。如果Partition机制设置合理，所有消息可以均匀分布到不同的Partition里，这样就实现了负载均衡。如果一个Topic对应一个文件，那这个文件所在的机器I/O将会成为这个Topic的性能瓶颈，而有了Partition后，不同的消息可以并行写入不同broker的不同Partition里，极大的提高了吞吐率。
🔔可以在$KAFKA_HOME/config/server.properties中通过配置项num.partitions来指定新建Topic的默认Partition数量，也可在创建Topic时通过参数指定，同时也可以在Topic创建之后通过Kafka提供的工具修改。</description>
    </item>
    
  </channel>
</rss>